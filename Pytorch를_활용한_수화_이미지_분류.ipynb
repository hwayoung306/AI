{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwayoung306/AI/blob/main/Pytorch%EB%A5%BC_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%88%98%ED%99%94_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef4591ca-acef-4cf4-9b59-25e073e75333"
      },
      "source": [
        "# 수화 이미지 분류 경진대회 Baseline1\n",
        "\n",
        "이번 대회는 주어진 수화 이미지의 숫자를 분류하는 대회입니다.\n",
        "\n",
        "단순 이미지 분류 문제이지만 이미지 처리를 처음 시작하시는 분들은 아마도 막막하실 겁니다.\n",
        "\n",
        "따라서 간단한 CNN 모델로 숫자 1, 2, 3, 4, 5, 6, 7, 8, 9, 10-1, 10-2 중 이미지들을 올바른 라벨로 분류하는 코드를 제공해드립니다.\n",
        "\n",
        "베이스라인을 통해 이미지 처리 기초에 입문해보세요!\n",
        "\n",
        "<!-- 이번 베이스라인 코드에서는 pytorch를 활용해 단순 CNN 모델을 사용하여 이미지 분류를 해보았습니다.\n",
        "CNN 을 활용한 알고리즘은 컴퓨터 비전 분야의 기초가 되는 알고리즘입니다! \n",
        "그럼 코드와 설명을 보고 CNN 알고리즘을 이해해 봅시다! \n",
        "\n",
        "* 코드를 어떻게 실행시켜야 할지 잘 모르시는 분은 아래 \"코랩으로 데이콘 참여하기\"를 먼저 봐주세요!\n",
        "https://dacon.io/competitions/official/235836/talkboard/404882\n",
        "\n",
        "* 데이터를 살펴보는 탐색적 데이터 분석 (Exploratory Data Analysis, EDA) 코드를 먼저 보고 오시면 좋습니다.-->\n"
      ],
      "id": "ef4591ca-acef-4cf4-9b59-25e073e75333"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpGD1duDcY_I",
        "outputId": "0d341c5c-13b6-45ba-a887-85ec31063c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "lpGD1duDcY_I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ce4b92e-f5d0-49e9-b8d0-19667383a701"
      },
      "source": [
        "## Convolutional Neural Network (CNN)\n",
        "코드로 들어가기 전 먼저 간단하게 CNN 모델을 이해하기 위한 기본 개념들을 둘러보겠습니다.\n",
        "\n",
        "## Neural Network (신경망)\n",
        "신경망은 다른 말로 인공 신경망(Artificial Neural Network)이라고도 불립니다.\n",
        "\n",
        "신경망이란 뇌 속 뉴런의 망형 구조를 닮은 다층형 구조의 컴퓨팅 모델입니다.   \n",
        "여기에는 서로 연결된 처리 소자, 일명 '뉴런'이라는 것이 있으며 생물학적 뉴런을 수학적으로 모델링한 것인데,   \n",
        "이들이 서로 협력하여 출력 함수를 도출합니다.   \n",
        "\n",
        "신경망은 입력 및 출력 계층/차원으로 구성되며 대부분은 숨겨진 계층도 있습니다.   \n",
        "숨겨진 계층은 입력을 출력 계층에서 사용할 수 있는 무언가로 변환해주는 단위로 구성됩니다.  \n",
        "따라서 인공신경망 뉴런은 여러 입력값을 받아 일정 수준을 넘어서게 되면 활성화되고 출력값을 내보냅니다."
      ],
      "id": "9ce4b92e-f5d0-49e9-b8d0-19667383a701"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a35d8852-f073-42d5-b53d-5b427378f8e1"
      },
      "source": [
        "### 1. Activation Function (활성화 함수)\n",
        "\n",
        "딥러닝 네트워크에서 노드에 입력된 값들을 비선형 함수에 통과시킨 후 다음 레이어로 전달하는데,    \n",
        "이 때 사용하는 함수를 활성화 함수(Activation Function)라고 합니다.\n",
        "\n",
        "선형 함수가 아니라 비선형 함수를 사용하는 이유는 딥러닝 모델의 레이어 층을 깊게 가져갈 수 있기 때문입니다.\n",
        "\n",
        "그럼 대표적인 활성화 함수 몇가지만 보겠습니다.\n",
        "\n",
        "#### 1) Sigmoid\n",
        "Sigmoid 함수는 Logistic 함수라고 불리기도 하며, x의 값에 따라 0~1의 값을 출력하는 S자형 함수입니다.  \n",
        "sigmoid 함수는 활성화 함수(Activation function)로 많이 사용되며 보통 0.5 미만은 0, 이상은 1을 출력하게 됩니다.\n",
        "\n",
        "sigmoid(x) = 1 / 1 + exp(-x)   \n",
        "그래프는 다음과 같습니다."
      ],
      "id": "a35d8852-f073-42d5-b53d-5b427378f8e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86a05a9-677f-4fd5-ab94-b90378abde6c"
      },
      "source": [
        "그러나 이런 sigmoid 함수에는 단점이 있습니다.\n",
        "\n",
        "그래프를 보시면 양 극단 값의 기울기(미분값)이 0에 가까워져 학습이 되지 않는 문제가 발생합니다.     \n",
        "이를 Gradient Vanishing 문제라고 하는데 이러한 문제를 해결하기 위해 다양한 활성화 함수들이 고안되었습니다.   "
      ],
      "id": "f86a05a9-677f-4fd5-ab94-b90378abde6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f34d707-c0b4-4120-8fee-294f41339e73"
      },
      "source": [
        "#### 2) ReLU\n",
        "ReLU 함수는 그렇게 고안된 활성화 함수 중 하나로, Gradient Vanishing 문제를 해결 가능합니다.\n",
        "\n",
        "relu(x) = 0 if x < 0 else max(0,x)\n",
        "위 식과 같이 ReLU 함수는 입력값을 0과 비교해 둘 중 큰 값을 출력합니다.\n",
        "\n",
        "따라서 계산이 빠르고 양 극단값이 포화되지 않는다는 장점이 있습니다.\n",
        "\n",
        "그러나 여전히 음수인 경우에는 0을 출력하여 학습이 이루어지지 않는다는 단점이 존재합니다."
      ],
      "id": "5f34d707-c0b4-4120-8fee-294f41339e73"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81d86a89-e0d4-4021-9ad1-6f9b5d5285be"
      },
      "source": [
        "### 2. Perceptron (퍼셉트론)\n",
        "퍼셉트론이란 신경망의 기원이 되는 개념으로, Frank Rosenblatt이 1957년 고안한 알고리즘입니다.\n",
        "\n",
        "이는 여러 신호를 입력받아 0(흐르지 않는다) 또는 1(흐른다)이라는 출력값을 앞으로 전달합니다.\n",
        "\n",
        "각 입력 신호 X는 각 가중치 w와 곱해집니다. 가중치가 클수록 그 신호가 중요하다는 뜻입니다.\n",
        "\n",
        "그러나 퍼셉트론은 단순한 선형 분류기로, AND나 OR과 같은 분류는 가능하나 XOR 분류는 불가능합니다."
      ],
      "id": "81d86a89-e0d4-4021-9ad1-6f9b5d5285be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5e11875-2d88-4c78-903a-5dd6be501a39"
      },
      "source": [
        "### 3. MLP(Multi-Layer Perceptron 다층 퍼셉트론)\n",
        "\n",
        "직선형 영역만 표시할 수 있는 단층 퍼셉트론의 한계를 극복하기 위해 고안된 것이 다층 퍼셉트론입니다.\n",
        "\n",
        "XOR 문제의 경우 각 영역을 직선으로 분리가 불가능한데, 비선형 영역까지 표현 가능한 다층 퍼셉트론으로 XOR 게이트까지 구현할 수 있습니다.\n"
      ],
      "id": "d5e11875-2d88-4c78-903a-5dd6be501a39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d2596aa-e4f7-4bef-8d14-847ce76638e5"
      },
      "source": [
        "## 환경 설정 및 데이터 로드\n",
        "이제 CNN 실습에 들어가보겠습니다.   \n",
        "우선 GPU를 쓸수 있는 환경이면 GPU 부터 할당해보도록 하겠습니다."
      ],
      "id": "5d2596aa-e4f7-4bef-8d14-847ce76638e5"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "910728fe-552e-49e7-a506-f348cbd6a139"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') #GPU 할당"
      ],
      "id": "910728fe-552e-49e7-a506-f348cbd6a139"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0019cb0-af83-4b0f-afdf-4c48014b229a"
      },
      "source": [
        "하이퍼 파라미터 값을 지정하겠습니다.    \n",
        "하이퍼 파라미터에 대한 설명은 진행하면서 설명드리겠습니다."
      ],
      "id": "e0019cb0-af83-4b0f-afdf-4c48014b229a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "39ca54cf-89b3-4aea-9227-f34c0de160f2"
      },
      "outputs": [],
      "source": [
        "#하이퍼 파라미터 튜닝\n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':32, #이미지 사이즈\n",
        "    'EPOCHS':50, #에포크 : 학습 횟수\n",
        "    'LEARNING_RATE':1e-3, #학습률\n",
        "    'BATCH_SIZE':12, #배치사이즈 : 몇 개의 샘플로 가중치를 갱신할 것인지 설정\n",
        "    'SEED':41, #시드\n",
        "}"
      ],
      "id": "39ca54cf-89b3-4aea-9227-f34c0de160f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb632df0-a41c-4a17-8a2e-81b29509325d"
      },
      "source": [
        "모델의 재현성을 위하여 random seed를 고정하겠습니다."
      ],
      "id": "cb632df0-a41c-4a17-8a2e-81b29509325d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a6422473-9876-43f9-8bd0-4ef94e8ce3a1"
      },
      "outputs": [],
      "source": [
        "# Seed 고정\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # 하이퍼파라미터 5번 셀 정의 SEED = 41"
      ],
      "id": "a6422473-9876-43f9-8bd0-4ef94e8ce3a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22ea2a4b-a936-40a8-a7d5-c39300aaf000"
      },
      "source": [
        "먼저 csv 파일을 불러와서 label이 어떻게 되어있는지 살펴보겠습니다."
      ],
      "id": "22ea2a4b-a936-40a8-a7d5-c39300aaf000"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFkieZtkKGWS",
        "outputId": "2bb2657a-5008-482f-b719-e2b71926f3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls "
      ],
      "id": "AFkieZtkKGWS"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ebc00966-da82-4cfd-85f5-60f8d18003b3",
        "outputId": "183fdaef-3833-4a1b-f926-4feea9757388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  file_name label\n",
              "0   001.png  10-2\n",
              "1   002.png  10-1\n",
              "2   003.png     3\n",
              "3   004.png     8\n",
              "4   005.png     9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04efbd9e-6a32-4dce-8287-19ee187fff70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.png</td>\n",
              "      <td>10-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.png</td>\n",
              "      <td>10-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.png</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04efbd9e-6a32-4dce-8287-19ee187fff70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04efbd9e-6a32-4dce-8287-19ee187fff70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04efbd9e-6a32-4dce-8287-19ee187fff70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "label_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/user_data/train.csv')\n",
        "label_df.head()"
      ],
      "id": "ebc00966-da82-4cfd-85f5-60f8d18003b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NHT7YGZz0-Mj",
        "outputId": "1b154948-c07f-46ad-cbea-a2767fd13d76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f2ac745-05aa-4307-b0b0-5743be9a38c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f2ac745-05aa-4307-b0b0-5743be9a38c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f2ac745-05aa-4307-b0b0-5743be9a38c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f2ac745-05aa-4307-b0b0-5743be9a38c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  file_name\n",
              "0   001.png\n",
              "1   002.png\n",
              "2   003.png\n",
              "3   004.png\n",
              "4   005.png"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# label_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/user_data/test.csv')\n",
        "# label_df.head()"
      ],
      "id": "NHT7YGZz0-Mj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbc92c9f-8d13-4082-b85f-9c20522c5d5c",
        "outputId": "4c14d2af-bc1a-4b64-eadf-df7297cc03a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 858 entries, 0 to 857\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  858 non-null    object\n",
            " 1   label      858 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 13.5+ KB\n"
          ]
        }
      ],
      "source": [
        "label_df.info()"
      ],
      "id": "bbc92c9f-8d13-4082-b85f-9c20522c5d5c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46ed2630-0a2d-469a-8c46-cb83f3dcce42"
      },
      "source": [
        "label이 object 타입으로 되어있는 것을 확인할 수 있습니다.   \n",
        "또한 10을 나타내는 수화 사진이 10-1, 10-2로 두가지로 분류되어있는 것을 알 수 있습니다.   "
      ],
      "id": "46ed2630-0a2d-469a-8c46-cb83f3dcce42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d6417ae-d0c8-48d1-958d-345697e82873"
      },
      "source": [
        "## 데이터 전처리"
      ],
      "id": "1d6417ae-d0c8-48d1-958d-345697e82873"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc3ac02e-231c-4e7b-894e-0adc46d62a90"
      },
      "source": [
        "모델링을 하기 위해 label을 정수형으로 수정해 주겠습니다.   \n",
        "파이토치는 클래스의 인덱스 번호가 0부터 읽어들이기 때문에,   \n",
        "10-1를 정수 10으로, 10-2를 정수 0으로 바꿔주고   \n",
        "label 열의 타입을 int로 수정해 주겠습니다."
      ],
      "id": "fc3ac02e-231c-4e7b-894e-0adc46d62a90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvKLH11rMxpK",
        "outputId": "aeae8756-f833-47ec-80b7-ffb1918fe09f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1     10-1\n",
              "13    10-1\n",
              "21    10-1\n",
              "22    10-1\n",
              "24    10-1\n",
              "Name: label, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 라벨이 10-1인것\n",
        "label_df['label'][label_df['label'] == '10-1'].head()"
      ],
      "id": "bvKLH11rMxpK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIxQRBxgNCn7",
        "outputId": "530bb128-9dfa-4cbd-b291-119c5a5b428b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     10-2\n",
              "7     10-2\n",
              "16    10-2\n",
              "28    10-2\n",
              "41    10-2\n",
              "Name: label, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 라벨이 10-2인것\n",
        "label_df['label'][label_df['label'] == '10-2'] .head()"
      ],
      "id": "JIxQRBxgNCn7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iowxgYXHNsP5"
      },
      "outputs": [],
      "source": [
        "label_df['label'][label_df['label'] == '10-1'] = 10 ## label : 10-1 -> 10\n",
        "label_df['label'][label_df['label'] == '10-2'] = 0 ## Label : 10-2 -> 0\n",
        "label_df['label'] = label_df['label'].astype(int) ## type을 object에서 int로 변경"
      ],
      "id": "iowxgYXHNsP5"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "11051eb5-cfa3-453d-b335-f217d297d5f3"
      },
      "outputs": [],
      "source": [
        "label_df['label'][label_df['label'] == '10-1'] = 10 ## label : 10-1 -> 10\n",
        "label_df['label'][label_df['label'] == '10-2'] = 0 ## Label : 10-2 -> 0\n",
        "label_df['label'] = label_df['label'].apply(lambda x : int(x)) ## Dtype : object -> int"
      ],
      "id": "11051eb5-cfa3-453d-b335-f217d297d5f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a827ee94-09b8-47f0-84d8-aee463907f63",
        "outputId": "8107397e-3f24-4ac4-8d9c-e8bccca7b2d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b9afdf14-d2d8-42c9-89ca-b8247d9d0939\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.png</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.png</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9afdf14-d2d8-42c9-89ca-b8247d9d0939')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9afdf14-d2d8-42c9-89ca-b8247d9d0939 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9afdf14-d2d8-42c9-89ca-b8247d9d0939');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  file_name  label\n",
              "0   001.png      0\n",
              "1   002.png     10\n",
              "2   003.png      3\n",
              "3   004.png      8\n",
              "4   005.png      9"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_df.head()"
      ],
      "id": "a827ee94-09b8-47f0-84d8-aee463907f63"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f92fa75-b270-4476-8380-a1ba5d8f9ede",
        "outputId": "39df6347-572d-4f7b-f7e2-633c661233c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 858 entries, 0 to 857\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  858 non-null    object\n",
            " 1   label      858 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 13.5+ KB\n"
          ]
        }
      ],
      "source": [
        "label_df.info()"
      ],
      "id": "1f92fa75-b270-4476-8380-a1ba5d8f9ede"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "926cc0bb-ae28-4e86-8160-33ec09049957"
      },
      "source": [
        "head()에서 label 열과 info()에서 Dtype을 보면    \n",
        "정상적으로 수정된 것을 확인 할 수 있습니다."
      ],
      "id": "926cc0bb-ae28-4e86-8160-33ec09049957"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ed445e-0deb-40ec-8865-cff239000390"
      },
      "source": [
        "그리고 데이터 이미지의 local adress와 label 값을 list에 저장해주도록 하겠습니다."
      ],
      "id": "a8ed445e-0deb-40ec-8865-cff239000390"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6YtXn0YQzvg"
      },
      "outputs": [],
      "source": [
        "x = '/content/drive/MyDrive/Colab Notebooks/user_data/train/006.png'"
      ],
      "id": "A6YtXn0YQzvg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlt8iEYtnYEt",
        "outputId": "8ae2a6db-7e88-4d1d-9ef1-022b95954cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "006.png\n",
            "006\n"
          ]
        }
      ],
      "source": [
        "# 이미지의 local adress가 어떻게 분류되는지 확인\n",
        "print( x.split('/')[-1] ) # 파일 명만 가져오기\n",
        "print( x.split('/')[-1].split('.')[0] ) # 파일 명에서 확장자 빼고 사진 이름(숫자)만 가져오기"
      ],
      "id": "Wlt8iEYtnYEt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvvqA8tun2aT",
        "outputId": "d1566602-f7a5-4b63-c235-4b310d0c1179"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0\n",
              "1      10\n",
              "2       3\n",
              "3       8\n",
              "4       9\n",
              "       ..\n",
              "853     9\n",
              "854     1\n",
              "855     4\n",
              "856    10\n",
              "857     7\n",
              "Name: label, Length: 858, dtype: int64"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_df['label'] # 사진에 담긴 수화의 값"
      ],
      "id": "PvvqA8tun2aT"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c379d73d-7170-4896-86e0-eb87963f606e"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "def get_train_data_path(data_dir): # 학습시킬 데이터의 이미지 번호(X값)와 이미지 번호에 따른 결과(y값)\n",
        "    img_path_list = [] # 이미지 번호(X값)\n",
        "    \n",
        "    # get image path\n",
        "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
        "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0])) # 기준으로 오름차순\n",
        "                \n",
        "    return img_path_list\n",
        "\n",
        "def get_train_data_label(data_dir): # 학습시킬 데이터의 이미지 번호(X값)와 이미지 번호에 따른 결과(y값)\n",
        "    label_list = [] # 이미지 번호 사진에 담긴 수화의 값(y값)\n",
        "        \n",
        "    # get label\n",
        "    #label_df = pd.read_csv(data_dir+'/train.csv')\n",
        "    label_list.extend(label_df['label'])\n",
        "                \n",
        "    return label_list\n",
        "\n",
        "def get_test_data(data_dir): # 테스트할 데이터의 이미지 번호만(X값만)\n",
        "    img_path_list = [] # 이미지 번호(X값)\n",
        "    \n",
        "    # get image path\n",
        "    img_path_list.extend(glob(os.path.join(data_dir, '*.png')))\n",
        "    img_path_list.sort(key=lambda x:int(x.split('/')[-1].split('.')[0])) # 기준으로 오름차순\n",
        "\n",
        "    return img_path_list\n"
      ],
      "id": "c379d73d-7170-4896-86e0-eb87963f606e"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d1ebd199-a743-43b2-8acd-a21c2479766f"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터 중 전체 이미지 데이터, 전체 답\n",
        "all_img_path = get_train_data_path('/content/drive/MyDrive/Colab Notebooks/user_data/train')\n",
        "all_label = get_train_data_label('/content/drive/MyDrive/Colab Notebooks/user_data/train')\n",
        "# 테스트 데이터 중 전체 이미지 데이터(답이 없음)"
      ],
      "id": "d1ebd199-a743-43b2-8acd-a21c2479766f"
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path  = get_test_data('/content/drive/MyDrive/Colab Notebooks/user_data/test') "
      ],
      "metadata": {
        "id": "E3-qMSFG5Gcx"
      },
      "id": "E3-qMSFG5Gcx",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uTmO-irShBW",
        "outputId": "c51c2871-2030-4083-abe5-693a662154ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/Colab Notebooks/user_data/train/001.png', '/content/drive/MyDrive/Colab Notebooks/user_data/train/002.png']\n",
            "\n",
            "[0, 10, 3, 8, 9]\n",
            "\n",
            "['/content/drive/MyDrive/Colab Notebooks/user_data/test/001.png', '/content/drive/MyDrive/Colab Notebooks/user_data/test/002.png']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print( all_img_path[0:2] )      ; print() # 이미지 경로를 이미지 번호에 따라 오름차순 \n",
        "print( all_label[0:5] )         ; print() # 이미지에 따른 라벨\n",
        "print( test_img_path[0:2] )     ; print()  # 테스트 이미지 경로"
      ],
      "id": "6uTmO-irShBW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdpyBDK-PswJ"
      },
      "source": [
        "## 데이터 증식하기!\n",
        "데이터 2배로 증식하기"
      ],
      "id": "vdpyBDK-PswJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpaXkh54P1Ze"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "#다음 변수를 수정하여 새로 만들 이미지 갯수를 정합니다.\n",
        "num_augmented_images = 800"
      ],
      "id": "wpaXkh54P1Ze"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBQYkBl9P2Vw"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/user_data/train/'\n",
        "file_names = all_img_path\n",
        "total_origin_image_num = len(file_names)\n",
        "augment_cnt = 1"
      ],
      "id": "JBQYkBl9P2Vw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwXZcACzP33A"
      },
      "outputs": [],
      "source": [
        "# 추가된 데이터 저장\n",
        "new_img = []\n",
        "new_label = []\n",
        "\n",
        "for i in range(1, num_augmented_images):\n",
        "    change_picture_index = random.randrange(1, total_origin_image_num-1)\n",
        "    print(\"선택한 인덱스 : \", change_picture_index)\n",
        "    print(\"해당 파일 경로 + 파일명 : \", file_names[change_picture_index])\n",
        "    print(\"해당 사진 정답 : \", all_label[change_picture_index])\n",
        "    print(\"몇개 생성? : \", augment_cnt)\n",
        "    file_name = file_names[change_picture_index]\n",
        "\n",
        "    origin_image_path = file_path\n",
        "    print(\"원래 경로 : \", origin_image_path)\n",
        "    image = Image.open(file_name)\n",
        "    random_augment = random.randrange(1,4)\n",
        "    \n",
        "    if(random_augment == 1):\n",
        "        #이미지 좌우 반전\n",
        "        print(\"invert\")\n",
        "        inverted_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        inverted_image.save(file_path + str(858 + augment_cnt) + '.png')\n",
        "        new_label.append(all_label[change_picture_index])\n",
        "        new_img.append( str(858 + augment_cnt) + '.png' )\n",
        "        \n",
        "    elif(random_augment == 2):\n",
        "        #이미지 기울이기\n",
        "        print(\"rotate\")\n",
        "        rotated_image = image.rotate(random.randrange(-20, 20))\n",
        "        rotated_image.save(file_path + str(858 + augment_cnt) + '.png')\n",
        "        new_label.append(all_label[change_picture_index])\n",
        "        new_img.append( str(858 + augment_cnt) + '.png' )\n",
        "        \n",
        "    elif(random_augment == 3):\n",
        "        #노이즈 추가하기\n",
        "        img = cv2.imread(file_name)\n",
        "        print(\"noise\")\n",
        "        row,col,ch= img.shape\n",
        "        mean = 0\n",
        "        var = 0.1\n",
        "        sigma = var**0.5\n",
        "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
        "        gauss = gauss.reshape(row,col,ch)\n",
        "        noisy_array = img + gauss\n",
        "        noisy_image = Image.fromarray(np.uint8(noisy_array)).convert('RGB')\n",
        "        noisy_image.save(file_path + str(858 + augment_cnt) + '.png')\n",
        "        new_label.append(all_label[change_picture_index])\n",
        "        new_img.append( str(858 + augment_cnt) + '.png' )\n",
        "        \n",
        "    \n",
        "    augment_cnt += 1\n",
        "    "
      ],
      "id": "JwXZcACzP33A"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpvNPsMUQj9d",
        "outputId": "5dcff10e-35a2-4ce2-82f7-94d9ab822d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(858, 1657)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len( new_img ), len( new_label )"
      ],
      "id": "MpvNPsMUQj9d"
    },
    {
      "cell_type": "code",
      "source": [
        "#################타입보고 고치기 if문 돌려보기\n",
        "print( type( new_label ) )\n",
        "print( type( new_label[0]) )"
      ],
      "metadata": {
        "id": "JygU0RXt61W1"
      },
      "id": "JygU0RXt61W1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 원본 csv 파일에 데이터 넣기"
      ],
      "metadata": {
        "id": "tD98X4Bj2ijg"
      },
      "id": "tD98X4Bj2ijg"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "f = open('/content/drive/MyDrive/Colab Notebooks/user_data/train.csv','a', newline='')\n",
        "wr = csv.writer(f)\n",
        "for i in range(0, len(new_img)) :\n",
        "    if new_label[i] == 10 :\n",
        "        wr.writerow([new_img[i], 10-1])\n",
        "    elif new_label[i] == 0 :\n",
        "        wr.writerow([new_img[i], 10-2])\n",
        "    else :\n",
        "        wr.writerow([new_img[i], new_label[i]])\n",
        "    \n",
        "f.close()"
      ],
      "metadata": {
        "id": "iYYWIp202nJb"
      },
      "id": "iYYWIp202nJb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k_-W9VKQex5"
      },
      "outputs": [],
      "source": [
        "all_img_path = get_train_data_path('/content/drive/MyDrive/Colab Notebooks/user_data/train')\n",
        "all_label = get_train_data_label('/content/drive/MyDrive/Colab Notebooks/user_data/train')"
      ],
      "id": "6k_-W9VKQex5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66945185-5309-49db-905c-9c1940b6ae7d"
      },
      "source": [
        "## CustomDataset\n",
        "\n",
        "전체 dataset을 구성하는 단계입니다.  "
      ],
      "id": "66945185-5309-49db-905c-9c1940b6ae7d"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7c734df1-539b-4a77-9fb5-fb98cdf96d24"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets # 이미지 데이터셋 집합체\n",
        "import torchvision.transforms as transforms # 이미지 변환 툴\n",
        "\n",
        "from torch.utils.data import DataLoader # 학습 및 배치로 모델에 넣어주기 위한 툴\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None): #필요한 변수들을 선언\n",
        "        self.transforms = transforms\n",
        "        self.train_mode = train_mode\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "\n",
        "    def __getitem__(self, index): #index번째 data를 return\n",
        "        img_path = self.img_path_list[index]\n",
        "        # Get image data\n",
        "        image = cv2.imread(img_path)\n",
        "        if self.transforms is not None: # 변환하는 법을 지정했다면~!\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        if self.train_mode: # train_mode가 true라면 -> 학습 데이터라면?\n",
        "            label = self.label_list[index]\n",
        "            return image, label # index번째 사진과 label을 return\n",
        "        else:\n",
        "            return image        # 아니면 image만 리턴\n",
        "    \n",
        "    def __len__(self): #길이 return\n",
        "        return len(self.img_path_list) # 이미지가 몇개 있는지 return하는 듯"
      ],
      "id": "7c734df1-539b-4a77-9fb5-fb98cdf96d24"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc647014-94ac-4b98-9246-fcddbb8ed99a"
      },
      "source": [
        "#### Train / Validation Split\n",
        "\n",
        "그럼 학습시킬 데이터 셋과 검증할 데이터 셋을 분리해주도록 하겠습니다."
      ],
      "id": "fc647014-94ac-4b98-9246-fcddbb8ed99a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "546f671f-6426-4a56-bdae-018fb3df9b99"
      },
      "outputs": [],
      "source": [
        "# Train : Validation = 0.8 : 0.25 Split\n",
        "# Train에서도 모델을 학습하고 테스트 할 train set(train)과 test set(validation)으로 분류\n",
        "train_len = int(len(all_img_path)*0.75) # 몇개\n",
        "Vali_len = int(len(all_img_path)*0.25)  # 몇개\n",
        "\n",
        "train_img_path = all_img_path[:train_len]\n",
        "train_label = all_label[:train_len]\n",
        "\n",
        "vali_img_path = all_img_path[train_len:]\n",
        "vali_label = all_label[train_len:]# 데스트의 답"
      ],
      "id": "546f671f-6426-4a56-bdae-018fb3df9b99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "693b0790-be52-4163-9a47-64d74cacf458",
        "outputId": "539fc880-0a86-44d2-88d5-62d2b43e4b80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 총 길이 :  1657\n",
            "train set 길이 :  1242\n",
            "vaildation set 길이 :  414\n",
            "학습 + 확인 :  1656\n"
          ]
        }
      ],
      "source": [
        "print( '데이터 총 길이 : ', len(all_img_path) )\n",
        "print( 'train set 길이 : ', train_len )\n",
        "print( 'vaildation set 길이 : ', Vali_len )\n",
        "print( '학습 + 확인 : ',  train_len + Vali_len )"
      ],
      "id": "693b0790-be52-4163-9a47-64d74cacf458"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ccd82f-6974-4cd9-b40a-2092482112bb"
      },
      "source": [
        "train set은 643개, vaildation set은 214개로 나뉘어진 것을 확인할 수 있습니다.  \n",
        "그럼 나뉜 데이터 셋에서 이미지를 분석 하기 위해 이미지 변형(transform)을 적용해보도록 하겠습니다."
      ],
      "id": "91ccd82f-6974-4cd9-b40a-2092482112bb"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3eb4d8e3-2404-4ae5-8caa-61c63b3422e7"
      },
      "outputs": [],
      "source": [
        "# 이렇게 변형 하겠다고 정의 함\n",
        "train_transform = transforms.Compose([\n",
        "                    transforms.ToPILImage(), #Numpy배열에서 PIL이미지로\n",
        "                    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]), #이미지 사이즈 변형\n",
        "                    transforms.RandomHorizontalFlip(), # Horizontal Flip\n",
        "                    transforms.RandomRotation(degrees=10,interpolation=transforms.InterpolationMode.NEAREST),\n",
        "                    transforms.RandomPerspective(distortion_scale=.15,p=.15,interpolation=transforms.InterpolationMode.NEAREST),\n",
        "                    transforms.ToTensor(), #이미지 데이터를 tensor\n",
        "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) #이미지 정규화\n",
        "                    \n",
        "                    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                    transforms.ToPILImage(),\n",
        "                    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "                    ])"
      ],
      "id": "3eb4d8e3-2404-4ae5-8caa-61c63b3422e7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad381ec7-5d5b-4fca-b853-01d27c767b4e"
      },
      "source": [
        "## Dataloader\n",
        "Dataloader class는 batch(한번에 처리하는 샘플 사이즈)기반의 딥러닝모델 학습을 위해서 mini batch를 만들어주는 역할을 합니다. \n",
        "\n",
        "dataloader를 통해 dataset의 전체 데이터가 batch size로 나뉘게 됩니다. \n",
        "\n",
        "만들었던 dataset을 input으로 넣어주면 여러 옵션(데이터 묶기, 섞기, 알아서 병렬처리)을 통해 batch를 만들어 내는 것입니다."
      ],
      "id": "ad381ec7-5d5b-4fca-b853-01d27c767b4e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZIh0sevvgJF"
      },
      "source": [
        "* Train data를 DataLoader에 적용해 batch만들기"
      ],
      "id": "8ZIh0sevvgJF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47a89e66-3e90-4eb1-9f3a-42b67cf7f01e"
      },
      "outputs": [],
      "source": [
        "# Get Dataloader\n",
        "#CustomDataset class[ 25번째 셀 ] 를 통하여 train dataset생성\n",
        "train_dataset = CustomDataset(train_img_path, train_label, train_mode=True, transforms=train_transform)"
      ],
      "id": "47a89e66-3e90-4eb1-9f3a-42b67cf7f01e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBJJyf1svr2i"
      },
      "source": [
        "* Vaildation을 DataLoader에 적용해 batch만들기"
      ],
      "id": "qBJJyf1svr2i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGF83vSpvay1"
      },
      "outputs": [],
      "source": [
        "# vaildation 에서도 적용\n",
        "vali_dataset = CustomDataset(vali_img_path, vali_label, train_mode=True, transforms=test_transform)"
      ],
      "id": "QGF83vSpvay1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gPz6IG_8wkv"
      },
      "outputs": [],
      "source": [
        "for i in range(10): ## 데이터 수 10배 증가 (100배로 증가시키고나서 진행해봤지만 성능은 더 안좋아졌습니다. 0.78정도)\n",
        "    train_dataset+=CustomDataset(train_img_path, train_label, train_mode=True, transforms=train_transform)\n",
        "    vali_dataset += CustomDataset(vali_img_path, vali_label, train_mode=True, transforms=test_transform)"
      ],
      "id": "9gPz6IG_8wkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kxTwPlK8mD1"
      },
      "outputs": [],
      "source": [
        "# 만든 train dataset를 DataLoader에 넣어 batch 만들기\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0) #BATCH_SIZE : 12\n",
        "vali_loader = DataLoader(vali_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
      ],
      "id": "6kxTwPlK8mD1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91923a3c-cd7a-467b-83ca-c28cd2aca897",
        "outputId": "4d21d002-b30b-4b95-ced0-fa0bd3306872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total train imgs : 1242 / total train batches : 1139\n",
            "total valid imgs : 414 / total valid batches : 381\n"
          ]
        }
      ],
      "source": [
        "train_batches = len(train_loader)\n",
        "vali_batches = len(vali_loader)\n",
        "\n",
        "print('total train imgs :',train_len,'/ total train batches :', train_batches)\n",
        "print('total valid imgs :',Vali_len, '/ total valid batches :', vali_batches)"
      ],
      "id": "91923a3c-cd7a-467b-83ca-c28cd2aca897"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6603cc4-eb0f-4998-b623-c7b1ef354b88"
      },
      "source": [
        "배치 사이즈가 24이므로    \n",
        "train은 54 묶음 vaildation은 18 묶음으로 묶인 것을 볼 수 있습니다."
      ],
      "id": "f6603cc4-eb0f-4998-b623-c7b1ef354b88"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1db1a3-6407-4d2f-9ada-275d3b739095"
      },
      "source": [
        "## 이미지 및 shape 확인\n",
        "\n",
        "Dataloader를 통해서 이미지가 잘 넣어졌는지 확인해보도록 해보겠습니다.    \n"
      ],
      "id": "5a1db1a3-6407-4d2f-9ada-275d3b739095"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebe290b9-7ad5-4f00-8ed4-585ccad79fd3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_features, train_labels = next(iter(train_loader)) # iter는 반복 가능한 객체에서 이터레이터를 반환하고, \n",
        "# 특성          라벨=정답                               # next는 이터레이터에서 값을 차례대로 꺼냅니다. \n",
        "# 12개로 묶어서 12개씩 들어있음"
      ],
      "id": "ebe290b9-7ad5-4f00-8ed4-585ccad79fd3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj1_RcmGxTNr"
      },
      "outputs": [],
      "source": [
        "train_features[0]"
      ],
      "id": "Uj1_RcmGxTNr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsGRYcooxTJj",
        "outputId": "c19c952f-68c6-4b31-e039-f76174d81304"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4, 0, 0, 6, 2, 1, 5, 2, 3, 7, 0, 8])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels"
      ],
      "id": "xsGRYcooxTJj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "kD7ox5KdxC5v",
        "outputId": "cd61033f-9652-4020-a4fe-8e76fb3b9cd3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 10\n"
          ]
        }
      ],
      "source": [
        "img = train_features[0] # \n",
        "label = train_labels[0]\n",
        "plt.imshow(img[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "id": "kD7ox5KdxC5v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "427339b3-0b40-4e26-8aad-b824b5e1a0c2"
      },
      "source": [
        "이미지와 라벨이 정상적으로 출력된 것을 확인했습니다.\n",
        "\n",
        "그럼 torch의 shape가 옳바르게 입력이 되었는지 확인해보도록 하겠습니다."
      ],
      "id": "427339b3-0b40-4e26-8aad-b824b5e1a0c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cedcdb1-8052-4d4b-a655-8f04dadbb172",
        "outputId": "0f651cd6-06f7-4f91-dce1-c09e7bfe2aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([12, 3, 32, 32])\n",
            "Batch Labels shape: tensor([10,  2,  5, 10,  4, 10,  7,  9,  7, 10,  7,  4])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Batch Labels shape: {train_labels}\")"
      ],
      "id": "0cedcdb1-8052-4d4b-a655-8f04dadbb172"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8454eacb-69c7-4bc8-9e43-d05f10bad445"
      },
      "source": [
        "torch.Size([12, 3, 128, 128])는 (batch_size, channels, high, width)를 의미합니다.   \n",
        "Label의 shape를 보면 정상적으로 배치사이즈(12)만큼 나오는 것을 확인할 수 있습니다."
      ],
      "id": "8454eacb-69c7-4bc8-9e43-d05f10bad445"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f23af3a-3761-4f08-9139-fd9a82c4368a"
      },
      "source": [
        "## 모델 구조 정의\n",
        "\n",
        "이제 CNN 모델을 학습시키기 위한 데이터가 준비되었다면   \n",
        "모델 구조를 설정하는 단계로 넘어가겠습니다."
      ],
      "id": "2f23af3a-3761-4f08-9139-fd9a82c4368a"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Pp9dobAE_E7i"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch.nn as nn # 신경망들이 포함됨\n",
        "#import torch.nn.init as init # 텐서에 초기값을 줌\n",
        "\n",
        "class CNNclassification(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNclassification, self).__init__()\n",
        "        self.keep_prob = 0.5 ## dropout에서 쓰임\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            ##채널=1\n",
        "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(32),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2)) ## 절반으로 줄어듬\n",
        "        \n",
        "        \n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        \n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        \n",
        "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 363, bias=True)\n",
        "        # torch.nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')\n",
        "        \n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            self.fc1,\n",
        "            torch.nn.ReLU(), ##ReLU Sigmoid\n",
        "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
        "        \n",
        "        self.fc2 = torch.nn.Linear(363, 11, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.layer4(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "id": "Pp9dobAE_E7i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37254364-3b54-4185-a68d-761ad6ed1c49"
      },
      "outputs": [],
      "source": [
        "# from tqdm.auto import tqdm\n",
        "# import torch.nn as nn # 신경망들이 포함됨\n",
        "# #import torch.nn.init as init # 텐서에 초기값을 줌\n",
        "\n",
        "# class CNNclassification(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(CNNclassification, self).__init__()\n",
        "#         self.keep_prob = 0.5\n",
        "#         self.layer1 = torch.nn.Sequential( # 체널 1\n",
        "#             nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1), #cnn layer\n",
        "#             torch.nn.BatchNorm2d(32),\n",
        "#                     # input 필터(3) -> output 필터 (8)\n",
        "#             nn.ReLU(), #activation function\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
        "        \n",
        "#         self.layer2 = torch.nn.Sequential( # 체널 2\n",
        "#             nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), #cnn layer\n",
        "#             torch.nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(), #activation function\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
        "        \n",
        "#         self.layer3 = torch.nn.Sequential( # 체널 3\n",
        "#             nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), #cnn layer\n",
        "#             torch.nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(), #activation function\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2, padding=1)) #pooling layer\n",
        "        \n",
        "#         self.fc1 = torch.nn.Linear(4 * 4 * 128, 363, bias=True)\n",
        "#         # torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        \n",
        "#         self.layer4 = torch.nn.Sequential(\n",
        "#             self.fc1,\n",
        "#             torch.nn.ReLU(),\n",
        "#             torch.nn.Dropout(p=1 - self.keep_prob))\n",
        "        \n",
        "#         # L5 Final FC 625 inputs -> 10 outputs\n",
        "#         self.fc2 = torch.nn.Linear(363, 11, bias=True)\n",
        "#         torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "#         # self.layer4 = torch.nn.Sequential( # 체널 4\n",
        "#         #     nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=1), #cnn layer\n",
        "#         #     nn.ReLU(), #activation function\n",
        "#         #     nn.MaxPool2d(kernel_size=2, stride=2)) #pooling layer\n",
        "        \n",
        "#         # self.fc_layer = nn.Sequential(  # 체널 5\n",
        "#         #     nn.Linear(3136, 11) #fully connected layer(ouput layer) 덴스층\n",
        "#         # )    \n",
        "        \n",
        "#     def forward(self, x):\n",
        "        \n",
        "#         x = self.layer1(x) #1층\n",
        "        \n",
        "#         x = self.layer2(x) #2층\n",
        "         \n",
        "#         x = self.layer3(x) #3층\n",
        "        \n",
        "#         x = x.view(x.size(0), -1) #4층\n",
        "\n",
        "#         x = self.layer4(x)\n",
        "        \n",
        "#         # x = torch.flatten(x, start_dim=1) # N차원 배열 -> 1차원 배열\n",
        "        \n",
        "#         out = self.fc2(x)\n",
        "#         return out"
      ],
      "id": "37254364-3b54-4185-a68d-761ad6ed1c49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac43ecaf-a641-40f6-8a86-f4239c00b201"
      },
      "source": [
        "### Convoultion Layer\n",
        "\n",
        "Convolution Layer에서는 이미지의 특징(feature map)을 추출해내는 역할을 합니다.   \n",
        "\n",
        "입력 데이터가 주어지면 필터를 이용해 특징을 추출한 다음 아웃풋을 내보냅니다.   \n",
        "\n",
        "이 필터는 커널(Kernel) 혹은 가중치의 배열이라고도 부르며 이 값을 조정하는 것이 곧 학습을 의미합니다.   \n",
        "\n",
        "첫번째 Convolution Layer에서는 3x3 크기의 커널을 사용했습니다. 이는 곧 학습해야 할 가중치가 9개라는 뜻입니다.   \n",
        "<br>\n",
        "### Stride   \n",
        "커널을 이동시키는 거리입니다. 특별한 언급이 없다면 1로 가정합니다.   \n",
        "\n",
        "Convolution을 하게되면 입력 데이터의 크기가 자연스럽게 줄어들게 되는데, \n",
        "\n",
        "주변에 값이 0인 셀들을 추가(Padding)해서 입력 데이터의 크기를 유지시키기도 합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Padding\n",
        "zero padding은 이미지 주위에 0을 둘러서 이미지 데이터의 축소를 방지해주는 역할을 합니다.\n",
        "\n",
        "필터로 인해 특징이 추출되면 자연스럽게 크기가 작아지는데, \n",
        "\n",
        "이미지 벡터들 가장자리에 0을 채워 Convolution Layer를 통과할 때 크기를 동일하게 유지시켜줄 수 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### ReLU\n",
        "앞서 도입부에서 말씀 드린 것 처럼, ReLU는 활성화 함수 중 하나입니다.\n",
        "\n",
        "Gradient Vanishing 문제를 해결 가능하고 계산이 빠르고 양 극단값이 포화되지 않는다는 장점이 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Pooling Layer - Max Pooling\n",
        "Pooling Layer는 데이터의 공간적 크기를 축소하는데 사용합니다.\n",
        "\n",
        "보통 이 레이어에서 이미지의 크기를 조절하며, CNN에서는 주로 Max-Pooling 방식을 사용합니다.\n",
        "\n",
        "Conv layer 는 이미지의 특정 영역의 특징을 잡아내는 역할이라면, \n",
        "\n",
        "Pooling 은 이미지의 크기를 줄이는 동시에 이미지의 전체의 특징 또한 보존합니다.\n",
        "\n",
        "따라서 Pooling 은 모델로 하여금 이미지 전체를 볼 수 있게 도와줍니다.\n",
        "\n",
        "Max Pooling에서는 선택된 영역에서 가장 큰 값을 뽑아 대표값으로 설정하는 방식입니다.\n",
        "\n",
        "이를 통해 학습 시간을 단축하고 오버피팅 문제를 완화할 수 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Fully Connected (output) Layer\n",
        "\n",
        "이전 레이어의 출력을 평탄화하여 다음 스테이지의 입력이 될 수 있는 단일 벡터로 변환합니다.\n",
        "\n",
        "마지막으로 각 라벨에 대한 최종 확률을 제공합니다."
      ],
      "id": "ac43ecaf-a641-40f6-8a86-f4239c00b201"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2550bf21-4ab0-4ab3-8fdd-b9667c9fb026"
      },
      "source": [
        "## 모델 학습\n",
        "\n",
        "이제 모델 학습을 하기 위해 매개변수를 정의해보도록 하겠습니다."
      ],
      "id": "2550bf21-4ab0-4ab3-8fdd-b9667c9fb026"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7a74888-75cd-4743-abc8-d81908201cd0"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim # 최적화 알고리즘들이 포함힘\n",
        "\n",
        "model = CNNclassification().to(device)  # device = gpu\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"]) # LEARNING_RATE : 2e-2 = 학습률\n",
        "scheduler = None"
      ],
      "id": "f7a74888-75cd-4743-abc8-d81908201cd0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4db9c57d-81d3-46d1-9fd1-b420eef2a5d6"
      },
      "source": [
        "이번 베이스라인에서는 모델은 기본 CNN classification 모델을 사용했습니다.\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "손실함수로는 classification 문제이기 때문에 'CrossEntropyLoss'를 사용했습니다.\n",
        "\n",
        "손실함수는 실제 값과 모델이 예측한 값의 거리를 출력하는 함수 입니다.\n",
        "\n",
        "쉽게 말해 손실함수는 모델의 예측이 얼마나 틀렸는지를 알려주는 함수 입니다.\n",
        "\n",
        "이 때 \"모델의 예측이 얼마나 틀렸는지\" 를 어떻게 정의하느냐에 따라 어떤 Loss Function 을 사용할 지가 정해지는 것 입니다.\n",
        "\n",
        "### Optimizer \n",
        "\n",
        "최적화 함수로는 확률적 경사 하강법인 'SGD(Stochastic Gradient Descent)'를 사용했습니다. \n",
        "\n",
        "Optimizer는 학습 데이터(Train data)셋을 이용하여 모델을 학습 할 때 데이터의 실제 결과와 모델이 예측한 결과를 기반으로 잘 줄일 수 있게 만들어주는 역할을 합니다.\n",
        "\n",
        "여기서 learning rate, 학습률은 얼마나 빠른속도로 이동할것이냐 입니다.\n",
        "\n",
        "learning rate를 엄청 크게 설정한다면 원하는 값까지 빠르게 도달할 수 있지만 자칫하면 오히려 최소값을 계산하도록 수렴하지 못합니다.\n",
        "\n",
        "반면 너무 작은 경우는 시간이 매우 오래걸립니다.\n",
        "\n",
        "따라서 적절한 learning rate설정이 중요합니다.\n",
        "\n",
        "이제 train 메소드를 통하여 train을 학습 시켜 vaildation으로 평가하는 메소드를 작성해보겠습니다."
      ],
      "id": "4db9c57d-81d3-46d1-9fd1-b420eef2a5d6"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "E7Eun74L_VOR"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, scheduler, device): \n",
        "    model.to(device)\n",
        "    n = len(train_loader)\n",
        "    \n",
        "    #Loss Function 정의\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(1,CFG[\"EPOCHS\"]+1): #에포크 설정\n",
        "        model.train() #모델 학습\n",
        "        running_loss = 0.0\n",
        "            \n",
        "        for img, label in iter(train_loader): # tqdm\n",
        "            img, label = img.to(device), label.to(device) #배치 데이터\n",
        "            optimizer.zero_grad() #배치마다 optimizer 초기화\n",
        "        \n",
        "            # Data -> Model -> Output\n",
        "            logit = model(img) #예측값 산출\n",
        "            loss = criterion(logit, label) #손실함수 계산\n",
        "            \n",
        "            # 역전파\n",
        "            loss.backward() #손실함수 기준 역전파 \n",
        "            optimizer.step() #가중치 최적화\n",
        "            running_loss += loss.item()\n",
        "              \n",
        "        print('[%d] Train loss: %.10f' %(epoch, running_loss / len(train_loader)))\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "            \n",
        "        #Validation set 평가\n",
        "        model.eval() #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
        "        vali_loss = 0.0\n",
        "        correct = 0\n",
        "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
        "            for img, label in iter(vali_loader): # tqdm\n",
        "                img, label = img.to(device), label.to(device)\n",
        "\n",
        "                logit = model(img)\n",
        "                vali_loss += criterion(logit, label)\n",
        "                pred = logit.argmax(dim=1, keepdim=True)  #11개의 class중 가장 값이 높은 것을 예측 label로 추출\n",
        "                correct += pred.eq(label.view_as(pred)).sum().item() #예측값과 실제값이 맞으면 1 아니면 0으로 합산\n",
        "        vali_acc = 100 * correct / len(vali_loader.dataset)\n",
        "        print('Vail set: Loss: {:.4f}, Accuracy: {}/{} ( {:.0f}%)\\n'.format(vali_loss / len(vali_loader), correct, len(vali_loader.dataset), 100 * correct / len(vali_loader.dataset))) \n",
        "        \n",
        "        #베스트 모델 저장\n",
        "        if best_acc < vali_acc:\n",
        "            best_acc = vali_acc\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/best_model.pth') #이 디렉토리에 best_model.pth을 저장\n",
        "            # print('Model Saved.')"
      ],
      "id": "E7Eun74L_VOR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de3664f4-0490-4337-8671-7455b5e12ac0"
      },
      "outputs": [],
      "source": [
        "# def train(model, optimizer, train_loader, scheduler, device): \n",
        "#     model.to(device)\n",
        "#     n = len(train_loader)\n",
        "    \n",
        "#     #Loss Function 정의\n",
        "#     criterion = nn.CrossEntropyLoss().to(device)\n",
        "#     best_acc = 0\n",
        "    \n",
        "#     for epoch in range(1, CFG[\"EPOCHS\"]+1): #에포크 설정 에포크 = 50\n",
        "#         model.train() #모델 학습\n",
        "#         running_loss = 0.0\n",
        "            \n",
        "#         for img, label in iter(train_loader): #배치데이터 넣기\n",
        "#             img, label = img.to(device), label.to(device) #배치 데이터\n",
        "#             optimizer.zero_grad() #배치마다 optimizer 초기화\n",
        "        \n",
        "#             # Data -> Model -> Output\n",
        "#             logit = model(img) #예측값 산출\n",
        "#             loss = criterion(logit, label) #손실함수 계산\n",
        "            \n",
        "#             # 역전파\n",
        "#             loss.backward() #손실함수 기준 역전파 \n",
        "#             optimizer.step() #가중치 최적화\n",
        "#             running_loss += loss.item()\n",
        "              \n",
        "#         print('[%d] Train loss: %.10f' %(epoch, running_loss / len(train_loader)))\n",
        "        \n",
        "#         if scheduler is not None:\n",
        "#             scheduler.step()\n",
        "            \n",
        "#         #Validation set 평가\n",
        "#         model.eval() #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
        "#         vali_loss = 0.0\n",
        "#         correct = 0\n",
        "#         with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
        "#             for img, label in iter(vali_loader):\n",
        "#                 img, label = img.to(device), label.to(device)\n",
        "\n",
        "#                 logit = model(img)\n",
        "#                 vali_loss += criterion(logit, label)\n",
        "#                 pred = logit.argmax(dim=1, keepdim=True)  #11개의 class중 가장 값이 높은 것을 예측 label로 추출\n",
        "#                 correct += pred.eq(label.view_as(pred)).sum().item() #예측값과 실제값이 맞으면 1 아니면 0으로 합산\n",
        "#         vali_acc = 100 * correct / len(vali_loader.dataset)\n",
        "#         print('vail set: 손실 : 손실 / 배치 사이즈, accuracy : 맞은예측합계 / 데이터의 전체길이 (예측률%)')\n",
        "#         print('Vail set: Loss: {:.4f}, Accuracy: {}/{} ( {:.3f}%)\\n'.format(vali_loss / len(vali_loader), correct, len(vali_loader.dataset), 100 * correct / len(vali_loader.dataset)))\n",
        "        \n",
        "#         #베스트 모델 저장\n",
        "#         if best_acc < vali_acc:\n",
        "#             print( vali_acc )\n",
        "#             best_acc = vali_acc\n",
        "#             torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/best_model.pth') #이 디렉토리에 best_model.pth을 저장\n",
        "#             print('Model Saved.')"
      ],
      "id": "de3664f4-0490-4337-8671-7455b5e12ac0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f696dac5-602f-4fa5-a593-878a9adbb0a6"
      },
      "source": [
        "dlclassification 문제이기 때문에 평가지표로는 Accuarcy를 사용하여 모델의 정확도를 산출하였습니다.\n",
        "\n",
        "### epoch\n",
        "딥러닝에서 epoch는 전체 트레이닝 셋이 신경망을 통과한 횟수입니다.\n",
        "\n",
        "1-epoch는 전체 트레이닝 셋이 하나의 신경망에 적용되어 순전파와 역전파를 통해 신경망을 한 번 통과했다는 뜻입니다.\n",
        "\n",
        "epoch 은 많을 수록 학습이 잘되는 것이 아닙니다.\n",
        "\n",
        "epoch 이 너무 적을 경우 학습이 덜 이루어지는 경우가 있고, epoch 이 너무 많을 경우 과적합이 되는 경우가 있습니다.\n",
        "\n",
        "따라서 적절한 epoch 을 설정해 주어야 합니다.\n",
        "\n",
        "이때 validation loss 와 accuracy 은 epoch 을 언제 중단 할지 모니터링 하는 용도로 사용되기도 합니다.\n",
        "\n",
        "### batch size\n",
        "batch size란 cpu 또는 gpu 연산 시, 하드웨어로 로드되는 데이터의 개수 입니다.\n",
        "\n",
        "본인의 컴퓨팅 환경에 따라 batch size 를 조절하는 것이 좋습니다.\n",
        "\n",
        "gpu 를 사용하는 경우 본인의 gpu 메모리 용량을 고려하여 batch size 를 설정해 주어야 합니다.\n",
        "\n",
        "batch size 는 모델 학습 과정에 영향을 끼치기도 합니다.\n",
        "\n",
        "따라서 하드웨어 상황을 고려하면서도 학습 과정 또한 고려하여 batch size 를 설정해 주어야 합니다.\n",
        "\n",
        "### Backpropagation (역전파)\n",
        "Backpropagation 오차 역전파법이라고도 하며 예측값과 실제값의 차이인 오차를 계산하고,\n",
        "\n",
        "이것을 다시 역으로 전파하여 가중치를 수정하여 오차가 작아지는 방향으로 일정 횟수를 반복해 수정하는 방법입니다.\n",
        "\n",
        "이때, 역전파 과정에서는 앞서 언급했던 최적화 함수를 이용합니다."
      ],
      "id": "f696dac5-602f-4fa5-a593-878a9adbb0a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CLc92IBV_Tq"
      },
      "outputs": [],
      "source": [
        "print('vail set: 손실 : 손실 / 배치 사이즈, accuracy : 맞은예측합계 / 데이터의 전체길이 (예측률%)')"
      ],
      "id": "1CLc92IBV_Tq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ab989d9-1668-4811-a4d9-706dd0f68c99",
        "outputId": "47ce2c41-e054-446e-de44-8778c2e71242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] Train loss: 1.5839004677\n",
            "Vail set: Loss: 1.0744, Accuracy: 2662/4565 ( 58%)\n",
            "\n",
            "[2] Train loss: 1.3733264742\n",
            "Vail set: Loss: 0.9436, Accuracy: 3069/4565 ( 67%)\n",
            "\n",
            "[3] Train loss: 1.2177251550\n",
            "Vail set: Loss: 0.7359, Accuracy: 3300/4565 ( 72%)\n",
            "\n",
            "[4] Train loss: 1.0768456637\n",
            "Vail set: Loss: 0.6043, Accuracy: 3586/4565 ( 79%)\n",
            "\n",
            "[5] Train loss: 0.9625104880\n",
            "Vail set: Loss: 0.6368, Accuracy: 3432/4565 ( 75%)\n",
            "\n",
            "[6] Train loss: 0.9224008885\n",
            "Vail set: Loss: 0.4464, Accuracy: 3982/4565 ( 87%)\n",
            "\n",
            "[7] Train loss: 0.8763067652\n",
            "Vail set: Loss: 0.3991, Accuracy: 3960/4565 ( 87%)\n",
            "\n",
            "[8] Train loss: 0.8092228141\n",
            "Vail set: Loss: 0.2993, Accuracy: 4213/4565 ( 92%)\n",
            "\n",
            "[9] Train loss: 0.7713328229\n",
            "Vail set: Loss: 0.3155, Accuracy: 4191/4565 ( 92%)\n",
            "\n",
            "[10] Train loss: 0.7431487156\n",
            "Vail set: Loss: 0.2290, Accuracy: 4334/4565 ( 95%)\n",
            "\n",
            "[11] Train loss: 0.7079610309\n",
            "Vail set: Loss: 0.2010, Accuracy: 4345/4565 ( 95%)\n",
            "\n",
            "[12] Train loss: 0.6648651145\n",
            "Vail set: Loss: 0.1745, Accuracy: 4378/4565 ( 96%)\n",
            "\n",
            "[13] Train loss: 0.6467039180\n",
            "Vail set: Loss: 0.2064, Accuracy: 4279/4565 ( 94%)\n",
            "\n",
            "[14] Train loss: 0.6167322748\n",
            "Vail set: Loss: 0.1782, Accuracy: 4334/4565 ( 95%)\n",
            "\n",
            "[15] Train loss: 0.5907839719\n",
            "Vail set: Loss: 0.1818, Accuracy: 4378/4565 ( 96%)\n",
            "\n",
            "[16] Train loss: 0.5641022326\n",
            "Vail set: Loss: 0.1403, Accuracy: 4422/4565 ( 97%)\n",
            "\n",
            "[17] Train loss: 0.5260278261\n",
            "Vail set: Loss: 0.1458, Accuracy: 4334/4565 ( 95%)\n",
            "\n",
            "[18] Train loss: 0.4982803122\n",
            "Vail set: Loss: 0.1393, Accuracy: 4433/4565 ( 97%)\n",
            "\n",
            "[19] Train loss: 0.4653885803\n",
            "Vail set: Loss: 0.1295, Accuracy: 4389/4565 ( 96%)\n",
            "\n",
            "[20] Train loss: 0.3868519453\n",
            "Vail set: Loss: 0.0731, Accuracy: 4477/4565 ( 98%)\n",
            "\n",
            "[21] Train loss: 0.3332630832\n",
            "Vail set: Loss: 0.0747, Accuracy: 4477/4565 ( 98%)\n",
            "\n",
            "[22] Train loss: 0.3329693819\n",
            "Vail set: Loss: 0.0800, Accuracy: 4477/4565 ( 98%)\n",
            "\n",
            "[23] Train loss: 0.2972994044\n",
            "Vail set: Loss: 0.0545, Accuracy: 4444/4565 ( 97%)\n",
            "\n",
            "[24] Train loss: 0.2685435599\n",
            "Vail set: Loss: 0.0469, Accuracy: 4510/4565 ( 99%)\n",
            "\n",
            "[25] Train loss: 0.2427888319\n",
            "Vail set: Loss: 0.0678, Accuracy: 4488/4565 ( 98%)\n",
            "\n",
            "[26] Train loss: 0.2225559128\n",
            "Vail set: Loss: 0.0582, Accuracy: 4455/4565 ( 98%)\n",
            "\n",
            "[27] Train loss: 0.1875923540\n",
            "Vail set: Loss: 0.0396, Accuracy: 4499/4565 ( 99%)\n",
            "\n",
            "[28] Train loss: 0.1728045105\n",
            "Vail set: Loss: 0.0332, Accuracy: 4521/4565 ( 99%)\n",
            "\n",
            "[29] Train loss: 0.1400277746\n",
            "Vail set: Loss: 0.0695, Accuracy: 4477/4565 ( 98%)\n",
            "\n",
            "[30] Train loss: 0.1435860073\n",
            "Vail set: Loss: 0.0250, Accuracy: 4554/4565 ( 100%)\n",
            "\n",
            "[31] Train loss: 0.1237004866\n",
            "Vail set: Loss: 0.0375, Accuracy: 4477/4565 ( 98%)\n",
            "\n",
            "[32] Train loss: 0.1090986875\n",
            "Vail set: Loss: 0.0551, Accuracy: 4521/4565 ( 99%)\n",
            "\n",
            "[33] Train loss: 0.0994770356\n",
            "Vail set: Loss: 0.0245, Accuracy: 4532/4565 ( 99%)\n",
            "\n",
            "[34] Train loss: 0.0910172461\n",
            "Vail set: Loss: 0.0357, Accuracy: 4499/4565 ( 99%)\n",
            "\n",
            "[35] Train loss: 0.0845277999\n",
            "Vail set: Loss: 0.0342, Accuracy: 4477/4565 ( 98%)\n",
            "\n",
            "[36] Train loss: 0.0787011067\n",
            "Vail set: Loss: 0.0532, Accuracy: 4488/4565 ( 98%)\n",
            "\n",
            "[37] Train loss: 0.0815914891\n",
            "Vail set: Loss: 0.0132, Accuracy: 4543/4565 ( 100%)\n",
            "\n",
            "[38] Train loss: 0.0749918913\n",
            "Vail set: Loss: 0.0273, Accuracy: 4499/4565 ( 99%)\n",
            "\n",
            "[39] Train loss: 0.0655451405\n",
            "Vail set: Loss: 0.0124, Accuracy: 4521/4565 ( 99%)\n",
            "\n",
            "[40] Train loss: 0.0752252495\n",
            "Vail set: Loss: 0.0250, Accuracy: 4521/4565 ( 99%)\n",
            "\n",
            "[41] Train loss: 0.0666597480\n",
            "Vail set: Loss: 0.0217, Accuracy: 4521/4565 ( 99%)\n",
            "\n",
            "[42] Train loss: 0.0594024790\n",
            "Vail set: Loss: 0.0213, Accuracy: 4521/4565 ( 99%)\n",
            "\n",
            "[43] Train loss: 0.0547079825\n",
            "Vail set: Loss: 0.0226, Accuracy: 4554/4565 ( 100%)\n",
            "\n",
            "[44] Train loss: 0.0547200022\n",
            "Vail set: Loss: 0.0108, Accuracy: 4543/4565 ( 100%)\n",
            "\n",
            "[45] Train loss: 0.0513086680\n",
            "Vail set: Loss: 0.0507, Accuracy: 4510/4565 ( 99%)\n",
            "\n",
            "[46] Train loss: 0.0538049959\n",
            "Vail set: Loss: 0.0400, Accuracy: 4510/4565 ( 99%)\n",
            "\n",
            "[47] Train loss: 0.0532160314\n",
            "Vail set: Loss: 0.0539, Accuracy: 4510/4565 ( 99%)\n",
            "\n",
            "[48] Train loss: 0.0422950219\n",
            "Vail set: Loss: 0.0355, Accuracy: 4543/4565 ( 100%)\n",
            "\n",
            "[49] Train loss: 0.0454934513\n",
            "Vail set: Loss: 0.0397, Accuracy: 4532/4565 ( 99%)\n",
            "\n",
            "[50] Train loss: 0.0455286571\n",
            "Vail set: Loss: 0.0428, Accuracy: 4521/4565 ( 99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, optimizer, train_loader, scheduler, device)"
      ],
      "id": "5ab989d9-1668-4811-a4d9-706dd0f68c99"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6e93f5d-b668-444a-8dd2-260d34f7aa82"
      },
      "source": [
        "에포크가 36일때 Vaildation Accuracy가 64%로 best_model에 선정되어 저장되었습니다."
      ],
      "id": "b6e93f5d-b668-444a-8dd2-260d34f7aa82"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be3c5e96-11f5-4b85-9f5b-e6bfa0cc7580"
      },
      "source": [
        "## 추론하기\n",
        "\n",
        "이제 학습된 best_model을 가지고 test 셋의 라벨을 추론해보도록 하겠습니다."
      ],
      "id": "be3c5e96-11f5-4b85-9f5b-e6bfa0cc7580"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "795e77b3-2ea3-4eaa-9db2-3c6c48353dfa"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_loader, device):\n",
        "    model.eval()\n",
        "    model_pred = []\n",
        "    with torch.no_grad():\n",
        "        for img in iter(test_loader):\n",
        "            img = img.to(device)\n",
        "\n",
        "            pred_logit = model(img)\n",
        "            pred_logit = pred_logit.argmax(dim=1, keepdim=True).squeeze(1)\n",
        "\n",
        "            model_pred.extend(pred_logit.tolist())\n",
        "    return model_pred"
      ],
      "id": "795e77b3-2ea3-4eaa-9db2-3c6c48353dfa"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QyD9DNJw8qX",
        "outputId": "e1dd002c-b3e2-46df-d95e-a777cebf6d42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 1, 6, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import cv2\n",
        "test_dataset = CustomDataset(test_img_path, None ,train_mode=False, transforms=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "# Validation Accuracy가 가장 뛰어난 모델을 불러옵니다.\n",
        "checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/best_model.pth')\n",
        "model = CNNclassification().to(device)\n",
        "model.load_state_dict(checkpoint)\n",
        "\n",
        "# Inference\n",
        "preds = predict(model, test_loader, device)\n",
        "preds[0:5]"
      ],
      "id": "6QyD9DNJw8qX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f37bb50-23d8-4426-bd95-ebea543c5dd6"
      },
      "source": [
        "값이 배열안에 정상적으로 잘 들어간 것을 확인할 수 있습니다."
      ],
      "id": "5f37bb50-23d8-4426-bd95-ebea543c5dd6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26f0871d-f0a5-45b0-9577-d6387a656008"
      },
      "source": [
        "## 제출하기"
      ],
      "id": "26f0871d-f0a5-45b0-9577-d6387a656008"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e627a7d-e435-474e-bffd-a00a6bd54e5e"
      },
      "source": [
        "submission에 예측한 값 preds를 넣어줍시다"
      ],
      "id": "0e627a7d-e435-474e-bffd-a00a6bd54e5e"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "53c2aa28-0420-403a-ac72-6137a0b2cbdd"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/user_data/sample_submission.csv')\n",
        "submission['label'] = preds"
      ],
      "id": "53c2aa28-0420-403a-ac72-6137a0b2cbdd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ca21c9-80cc-4176-8671-ab1f65c27a4b"
      },
      "source": [
        "이제 제출을 위해 라벨을 다시 복원 시켜 줍니다.\n",
        "\n",
        "앞서 10-1을 10으로, 10-2를 0으로 바꿔주었던 값을 다시 원래의 값으로 바꿔주겠습니다.\n",
        "\n",
        "또한 label 열의 타입을 int에서 object로 수정해 주겠습니다."
      ],
      "id": "c3ca21c9-80cc-4176-8671-ab1f65c27a4b"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4182c5c-7c77-4626-b960-54d841b3f212",
        "outputId": "2fe58590-d71f-4b8a-b5f0-da05a101e7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "submission['label'][submission['label'] == 10] = '10-1' ## label : 10 -> '10-1'\n",
        "submission['label'][submission['label'] == 0] = '10-2' ## Label : 0 -> '10-2'\n",
        "submission['label'] = submission['label'].apply(lambda x : str(x)) ## Dtype : int -> object"
      ],
      "id": "f4182c5c-7c77-4626-b960-54d841b3f212"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "82456b3b-7288-4759-8539-cbd3cf69079f",
        "outputId": "be235afd-330d-4434-dc97-2d1e2a5d5ed8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  file_name label\n",
              "0   001.png     1\n",
              "1   002.png     2\n",
              "2   003.png     1\n",
              "3   004.png     6\n",
              "4   005.png     8\n",
              "5   006.png  10-1\n",
              "6   007.png  10-1\n",
              "7   008.png     2\n",
              "8   009.png     4\n",
              "9   010.png     4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bbe2b74-07b3-45bc-9751-f366bc7e3ef9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.png</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.png</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>006.png</td>\n",
              "      <td>10-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>007.png</td>\n",
              "      <td>10-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>008.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>009.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>010.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bbe2b74-07b3-45bc-9751-f366bc7e3ef9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3bbe2b74-07b3-45bc-9751-f366bc7e3ef9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3bbe2b74-07b3-45bc-9751-f366bc7e3ef9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "submission.head(10)"
      ],
      "id": "82456b3b-7288-4759-8539-cbd3cf69079f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4890e01-35a4-45ad-b89f-85f52560fb2f"
      },
      "source": [
        "submission을 csv 파일로 저장합니다.   \n",
        "\n",
        "index=False란 추가적인 id를 부여할 필요가 없다는 뜻입니다.   \n",
        "\n",
        "정확한 채점을 위해 꼭 index=False를 넣어주세요."
      ],
      "id": "e4890e01-35a4-45ad-b89f-85f52560fb2f"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "f1b1f36f-d1b2-43b7-8acf-1cff3f3be8bb"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('/content/drive/MyDrive/Colab Notebooks/submit.csv', index=False)"
      ],
      "id": "f1b1f36f-d1b2-43b7-8acf-1cff3f3be8bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5d6fd9-e984-49d2-8547-d337186dbe7c"
      },
      "source": [
        "이렇게 생성된 submission.csv 파일을 데이콘 대회 페이지에 업로드 & 제출하여 결과를 확인해보세요!\n",
        "\n",
        "문제를 해결하기 위한 여러분의 방법을 코드 공유 게시판에 공유해주세요\n",
        "\n",
        "좋아요와 댓글을 합산하여 가장 높은 점수를 얻으신 분께 데이콘 후드가 제공됩니다!"
      ],
      "id": "7e5d6fd9-e984-49d2-8547-d337186dbe7c"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ac43ecaf-a641-40f6-8a86-f4239c00b201"
      ],
      "name": " Pytorch를 활용한 수화 이미지 분류.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "world",
      "language": "python",
      "name": "world"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}